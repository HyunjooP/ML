{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_Simple_Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga6vorOgpNRj"
      },
      "source": [
        "# 단순 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14iOHrUdpR4o"
      },
      "source": [
        "## 해석적 방법의 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCP0VLR0mqym"
      },
      "source": [
        "def costfunction(x, y, W, b, iters):\n",
        "  total = 0.0\n",
        "  for i in range(len(x)):\n",
        "    total += pow(W[iters]*x[i] +b[iters]- y[i], 2)\n",
        "  return total/2\n",
        "\n",
        "X = [157, 160, 160, 168, 172, 175, 175, 177, 182, 184, 188, 190]\n",
        "y = [42, 48, 54, 58, 63, 69, 71, 73, 70, 80, 79, 81]\n",
        "\n",
        "M1_W=[0.0]\n",
        "M1_b=[0.0]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFnUX4iQn5uL",
        "outputId": "02934c9d-1a95-4db5-bd9e-4c4f9c374f32"
      },
      "source": [
        "# Method 1: Statistical\n",
        "\n",
        "print('==============================================')\n",
        "print(' Method 1: Statistical Method')\n",
        "print('==============================================')\n",
        "Xmean = sum(X) / len(X)\n",
        "Ymean = sum(y) / len(y)\n",
        "print('Xmean:', Xmean, 'Ymean:', Ymean)\n",
        "print('----------------------------------------------')\n",
        "total1 = 0\n",
        "total2 = 0\n",
        "for i in range(len(X)):\n",
        "  total1 += (y[i] - Ymean)*(X[i]-Xmean)\n",
        "  total2 += pow(X[i]-Xmean, 2)\n",
        "M1_W[0] = total1/total2\n",
        "M1_b[0] = Ymean - M1_W[0]*Xmean\n",
        "print('Linear Regression by Methos 1 : y =', M1_W[0], '* x +', M1_b[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================\n",
            " Method 1: Statistical Method\n",
            "==============================================\n",
            "Xmean: 174.0 Ymean: 65.66666666666667\n",
            "----------------------------------------------\n",
            "Linear Regression by Methos 1 : y = 1.1164688427299703 * x + -128.59891196834815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2DHXHUVu4Ao"
      },
      "source": [
        "import random"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T0YwMX2pHV7",
        "outputId": "b86acef3-af49-4455-c8d3-7d124676a581"
      },
      "source": [
        "# Method 2\n",
        "\n",
        "print('=========================================')\n",
        "print('Method 2: Gradient Descent Method')\n",
        "print('=========================================')\n",
        "W=[0.0]\n",
        "b=[0.0]\n",
        "W[0] = float(random.randint(-100, 100))\n",
        "b[0] = float(random.randint(-100, 100))\n",
        "\n",
        "iters = 0\n",
        "cost = costfunction(X, y, W, b, iters)\n",
        "\n",
        "\n",
        "print(\"Iteration\", iters, \"\\tW[0]:\", W[0], \"\\tb[0]:\", b[0], \"\\tcost:\", cost)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================\n",
            "Method 2: Gradient Descent Method\n",
            "=========================================\n",
            "Iteration 0 \tW[0]: -50.0 \tb[0]: 40.0 \tcost: 458584705.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl5LxOFz1CkK"
      },
      "source": [
        "def g_W(x, y, iters):\n",
        "  total=0.0\n",
        "  for i in range(len(x)):\n",
        "    total += W[iters]*pow(x[i],2)+b[iters]*x[i]-x[i]*y[i]\n",
        "  return total\n",
        "\n",
        "\n",
        "def g_b(x, y, iters):\n",
        "  total=0.0\n",
        "  for i in range(len(x)):\n",
        "    total += W[iters]*x[i] + b[iters] - y[i]\n",
        "  return total"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0thIDoV4u1LI",
        "outputId": "45a41aeb-15e5-4479-d198-0cb73ce49649"
      },
      "source": [
        "rate = 10/cost\n",
        "MaxItrs = cost\n",
        "precision = 0.0001\n",
        "while cost > precision:\n",
        "  iters = iters+1\n",
        "  gradientW = g_W(X, y, iters-1)\n",
        "  gradientB = g_b(X, y, iters-1)\n",
        "  newW = W[iters-1] - rate * gradientW \n",
        "  newb = b[iters-1] - rate * gradientB\n",
        "  W.append(newW)\n",
        "  b.append(newb)\n",
        "\n",
        "  if iters %100==0:\n",
        "    print('ieration:', iters, end=',')\n",
        "    print('gradient W: %.1f, gradient b:%.1f, ' % (gradientW, gradientB), end=' ')\n",
        "    print('W[ %d ]:%.1f, b[%d]:%.1f, cost: %.1f'\n",
        "            % (iters, W[iters], iters, b[iters], cost))\n",
        "    ans = input()\n",
        "    if ans == 'q':\n",
        "      break"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ieration: 100,gradient W: -8296584.1, gradient b:-47497.8,  W[ 100 ]:-22.4, b[100]:40.2, cost: 458584705.0\n",
            "q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8597O-gdyq87"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    }
  ]
}